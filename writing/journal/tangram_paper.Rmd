---
title             : "Parents scaffold the formation of conversational pacts with their children"
shorttitle        : "Parents scaffold pacts"

author: 
  - name          : "XXXXX"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "XXXXX"
    email         : "XXXXX"
  - name          : "XXXXX"
    affiliation   : "1"
  - name          : "XXXXX"
    affiliation   : "1,2"

affiliation:
  - id            : "1"
    institution   : "XXXXX"
  - id            : "2"
    institution   : "XXXXX"

abstract: |
   Adults readily form pacts, or temporary agreements about referent names, over the course of conversation. Young children fail to do so with peers, but recent evidence suggests that explicit feedback from adults may improve their performance [@matthews2007]. Do parents naturally provide such structure in their conversations with children? Using a director-matcher paradigm, we first show that parents and children (ages 4, 6, 8) converge on increasingly accurate and efficient conversational pacts. Further, parents of younger children provide more interactive feedback. Finally, we analyze asymmetries in parents' and children's contributions, finding that pacts tend to originate with the parent, but are simplified by younger children. Together, these results support the idea that parents sensitively adapt their language to their children's developmental level to scaffold successful communication.
   
authornote: |
  All data and code for these analyses are available at https://osf.io/3f8hy/?view_only=9a196db0444c4867bc899cc70a7a1e9c. Videos of experiment sessions are available on Databrary.

keywords          : "parent-child interaction; language development; communication"
wordcount         : "1385"
references        : "42"

bibliography      : ["tangram.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r load-packages, include = FALSE}
library(png)
library(grid)
library(egg)
library(xtable)
library(knitr)
library(papaja)
library(entropy)
library(ggthemes)
library(lme4)
library(lmerTest)
library(directlabels)
library(ggrepel)
library(here)
library(scales)
library(tidyboot)
library(broom)
library(broom.mixed)
library(kableExtra)
library(english)
library(ggthemes)
library(effectsize)
library(glue)
library(tidyverse)
library(tidytext)
library(textstem)
library(entropy)
library(janitor)

theme_set(theme_few(base_size = 10) + theme(legend.position = "none"))

knitr::opts_chunk$set(fig.pos = '!tb', echo = FALSE, cache = TRUE, 
                      warning = FALSE, message = FALSE, 
                      sanitize = TRUE, fig.path='figs/', fig.width = 3,
                      fig.height = 3, fig.pos = "t!")
set.seed(42)
options(digits=3, dplyr.summarise.inform = FALSE)


CHILD_SCALE <- c("#9ecae1", "#4292c6", "#08519c")
COLLAPSED_SCALE <-c('#525252', '#737373','#969696')
ADULTS <- "black"
PARENTS <- "#fe9929"

```

```{r load-data}
kuperman_aoas <- read_csv(here("data/corpus_data/kuperman_aoas.csv"),
                          show_col_types = FALSE)
combined_data <- read_csv(here("data/deidentified/combined.csv"),
                          show_col_type = FALSE) 
exchanges_data <- read_csv(here("data/deidentified/exchanges.csv"),
                           show_col_types = FALSE) 
```

Common ground is a foundational requirement for successful communication: Interlocutors must both understand each other and know that they understand each other [@bruner1985]. As a consequence, even simple referential expressions are constructed collaboratively. When the meaning of an utterance is unclear, interlocutors will engage in negotiation, arriving at a *conversational pact* about how to think and talk about the intended referent [@clark1986]. Adults fluently form, revise, and track the formation of pacts. For instance, Brennan and Clark [-@brennan1996] showed that adults will use the appropriate level of specificity for a referent (e.g. "loafer" rather than "shoe" when another shoe is present), carry this forward into a new context with the same conversational partner even when the initial competitor is removed, then revert to "shoe" when a new partner is introduced.

Children, on the other hand, struggle substantially both to establish and to deploy conversational pacts. In a series of studies, Krauss and Glucksberg [-@krauss1977] asked pairs of age-matched children to play a director-matcher game that required them to refer to novel objects [see also @krauss1969]. Across repeated interactions with the same novel objects, 5- and 6-year-old children showed very little evidence of pact formation: The matcher's accuracy in selecting the correct referent remained low, and the director did not reduce of the length of their referential expressions as adults do. Older children showed some improvement on both measures, but even 10- and 11-year-olds were less successful than a comparison group of adults. 

While children struggle as directors, their performance can improve significantly when an adult offers explicit guidance on whether their referential expressions are ambiguous or otherwise insufficiently informative. For example, @deutsch1982 showed that clarification questions could be used by adults to eventually elicit unambiguous descriptions from 6- and 9-year-olds and, to a lesser extent, from 3-year-olds. A recent training study by @matthews2007 replicated this finding in 2- to 4-year-olds, and further showed transfer to a different communication task. While these studies show how adult input may help children produce informative referential expressions, it remains unclear whether, or how, adults provide such feedback in the course of natural adult-child conversations.

```{r ipads, fig.env = "figure*", fig.pos = "!ht", out.width = "450px", fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "(A) Tangram figures used as referential targets, (B) director and matcher displays, (C) trial sequence."}
# Note: this is moved up here to get the fig to appear on the right page... i know it's annoying.
knitr::include_graphics("figs/design.pdf")
```

Children engage in conversation with their caregivers from their second year of life and reciprocal social interaction even before that [@bruner1985]. Further, children's language development is predicted most strongly not by the amount of language they hear, but rather by the amount of conversational turns they engage in [@romeo2018]. Given that young children struggle with informativity and perspective-taking, how do conversations with caregivers succeed? One possibility is that parents naturally adopt some of the strategies used by experimenters in training studies of conversational pact formation: Pointing out when references are ambiguous, clarifying when children have produced insufficient information, and/or helping children to conceptualize their referential targets in better ways. Indeed, parents' contingent responses to children's incorrect or incomplete utterances have been implicated in language learning more broadly [@chouinard2003]. 

Parents spend a tremendous amount of time with children, and often have quite accurate models of their children's lexical and conceptual knowledge [@fenson1994]. Prior work has shown that parents leverage their knowledge of their children's vocabularies to calibrate the informativeness of their referential expressions [@leung2019]. Do they also leverage this knowledge to scaffold the formation of conversational pacts with children? In this study, we asked parents and their 4-, 6-, and 8-year-old children, as well as pairs of adults, to play an adapted version of Krauss and Glucksberg's [-@krauss1969] director-matcher game. We analyzed their interactions to ask (1) whether parents' contributions support the formation of conversational pacts, (2) what strategies parents use to support pact formation, and (3) whether the nature of these pacts changes over development as children acquire more language.

# Experiment 1: Referential communication

```{r acc-exchange-setup, cache = T}
# Note: this is moved up here to get the fig to appear on the right page... i know it's annoying.
d.accuracy.raw <- combined_data %>%
  ungroup() %>%
  mutate(age = as.character(age),
         age = if_else(is.na(age), 'adult', age)) %>%
  mutate(director = case_when(person == "parent" & role == "matcher" ~ "child",
                              person == "child" & role == "director" ~ "child",
                              T ~ "adult"),
         person = if_else(person %in% c('left', 'right', 'parent'), 
                         'adult', person)) %>%
  group_by(subid, director, trial, age, target, rep_num) %>%
  summarize(correct = mean(correct)) %>% # make sure each trial is only counted once
  ungroup()

# Bootstrap error bars 
result.acc.means <- d.accuracy.raw %>%
  group_by(director, age, rep_num) %>%
  tidyboot_mean(correct)


lmer.accuracy <- d.accuracy.raw %>%
  filter(age != "adult") %>%
  mutate(age = as.numeric(age)) %>%
  glmer(correct ~ age + rep_num + (rep_num | subid) + (1 | target), 
                            family = 'binomial', data = .) %>%
  tidy()

age_effect_acc = lmer.accuracy %>% filter(term == 'age')
rep_effect_acc = lmer.accuracy %>% filter(term == 'rep_num')


d.exchanges.raw <- exchanges_data %>%
  mutate(age = as.character(age),
         age = if_else(is.na(age), 'adult', age),
         director = case_when(person == "parent" & role == "matcher" ~ "child",
                              person == "child" & role == "director" ~ "child",
                              T ~ "adult")) %>%
  group_by(director, subid, trial, age, target, rep_num) %>%
  summarize(num_exchanges = n()) %>% 
  ungroup()

d.exchanges.mean <- d.exchanges.raw %>%
  group_by(director, age, rep_num) %>%
  tidyboot_mean(num_exchanges)

# Bootstrap error bars and plot
lmer.exchanges <- d.exchanges.raw %>% 
  filter(age != 'adult') %>%
  mutate(age = as.numeric(age)) %>%
  lmer(num_exchanges ~ age + rep_num +  (rep_num | subid) + (1 | target), 
       control = lmerControl(optimizer = "bobyqa"), data = .) %>%
  tidy()

age_effect_exchanges = lmer.exchanges %>% filter(term == 'age')
rep_effect_exchanges = lmer.exchanges %>% filter(term == 'rep_num')
```

```{r acc_exchanges, fig.width = 6, fig.height = 2.75, fig.align = "center", fig.cap = "(A) Accuracy improves over time for all groups. (B) Number of dialogue exchanges is higher for younger children. Error bars are 95\\% CIs. The drop in accuracy for 8-year-olds is likely an artifact of a small set of children losing interest in the task."}

# render plot
plt.results.acc <- result.acc.means %>%   
  ggplot(aes(x = rep_num, y = empirical_stat * 100,  
             group = director, color = director, label = director)) +
  geom_line(position = position_dodge(.25)) +
  geom_errorbar(aes(ymin = ci_lower * 100, ymax = ci_upper * 100),
                width = 0.05, position = position_dodge(.25)) +
  facet_grid(. ~ age) + 
  ylab("% accuracy") +
  xlab("repetition #") +
  ylim(70, 100) +
  scale_x_continuous(limits = c(.5, 4.25), breaks = 1:4) + 
  theme(aspect.ratio = 1 / 1.3, legend.position = "none") +
  scale_color_manual(values = c(rev(COLLAPSED_SCALE), ADULTS)) +
  labs(tag = 'A') + 
  geom_dl(method = list(dl.trans(x = x - .2), "first.qp", cex=.8))


# Bootstrap error bars and render plot
plt.results.exchanges <- d.exchanges.mean %>%
  ggplot(aes(x = rep_num, y = empirical_stat, color = director, 
             group = director, label = director)) +
  geom_line(position = position_dodge(.25)) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0,
                position = position_dodge(.25)) +
  ylab("# exchanges per round") +
  facet_grid(. ~ age) + 
  xlab("repetition #") +
  theme(aspect.ratio = 1 / 1.3 , legend.position = "none") +
  scale_color_manual(values = c(rev(COLLAPSED_SCALE), ADULTS)) +
  labs(tag = 'B') +
  scale_x_continuous(limits = c(.75, 4.5), breaks = 1:4) + 
  geom_dl(method = list(dl.trans(x = x + .2), "last.qp", cex=.8)) 

gridExtra::grid.arrange(plt.results.acc, plt.results.exchanges, ncol = 1)
```

## Methods

### Participants

Children (ages 4, 6, and 8) and their parents were recruited from a database of families in the local community to achieve a planned sample of 60 parent-child pairs (20 per age group). A total of 75 children and their parents participated. Data from 12 pairs were dropped due to failure to complete the study, leaving a final sample of 63 pairs. For comparison, adult participants were also recruited from a Psychology Department subject pool to achieve a planned control sample of 20 adult-adult pairs. At the time of analysis, only 15 of these pairs had their sessions transcribed.

### Stimuli 

Twelve solid black images of tangrams were normed on Amazon Mechanical Turk for pairwise similarity. Each of the 60 participants made 22 pairwise similarity judgments on a scale from 1-100. Based on these similarity ratings ($M$ = 42.3, $SD$ = 26.1), the ten most dissimilar tangrams were selected for use as stimuli (Fig. \ref{fig:ipads}A).

### Design and procedure

Pairs of participants were brought into the lab to play a cooperative director-matcher game. They were seated in front of iPads at opposite ends of a table, with a divider preventing them from seeing each other's screens. Participants were told that they would take turns playing *director* and *matcher* roles. The director's task was to describe the *target* image, privately indicated by a blue border, and the matcher's task was to select one of the images on their screen based on the director's description (Fig. \ref{fig:ipads}B). Before beginning the experiment, participants played six practice trials with images of common fruits and vegetables. 

The experiment consisted of four repetition blocks of ten trials each (Fig. \ref{fig:ipads}C). Each tangram was the target once per block. We constructed the trial sequence to ensure that participants both alternated roles from trial to trial and alternated roles for each *target* from block to block. For each participant pair, we randomly divided the tangrams into two sets of five: the adult was assigned one set to describe on the first block, and the child was assigned the other set. These sets were interleaved on the first block, such that players alternated roles. On each subsequent block, these sets were swapped such that each tangram was described by each participant exactly twice over the course of the experiment. 

On each trial, the target tangram appeared with a foil selected from the set of nine other tangrams.
Targets appeared with different foils on different repetition blocks. To ensure that the game would not be too difficult for young children, tangrams most similar to the target (based on similarity norms) did not appear as foils. To discourage participants from using spatial language (e.g. "left side"), the target and foil were shown in randomized order across the two iPads. When the matcher selected an image, it became colorful and a pleasant sound played. Importantly, neither the matcher nor director received feedback about accuracy: the same sound played whether the selection was correct or not.

### Pre-processing

Sessions were videotaped and subsequently transcribed using Datavyu [-@datavyu-team2014], an open source coding program. Each video was transcribed and checked by two different coders. Utterances were manually coded as part of a trial or unrelated to the game (e.g. "sit down please"), and unrelated utterances were removed before analysis.

```{r reduction-setup, cache = TRUE}
d.reduction.raw <- exchanges_data %>%
  mutate(age = ifelse(is.na(age), 'adult', age),
         num_words =  str_count(utterance, " ") +1) %>%
  filter(role == 'director') %>%
  mutate(person = ifelse(person %in% c('left', 'right', 'parent'), 'adult', person)) %>%
  group_by(age, rep_num, person, target, subid, trial) %>%
  summarize(numExchanges = n(),
            num_words = sum(num_words)) %>%
  mutate(normalized_num_words = num_words / numExchanges) %>%
  ungroup() 

d.reduction.means <- d.reduction.raw %>% 
  group_by(age, rep_num, person) %>%
  tidyboot_mean(normalized_num_words) %>%
  mutate(plot_person = case_when(age == "adult" ~ "adult",
                                 person == "adult" ~ "parent",
                                 T ~ "child"))
```

## Results

We characterized developmental differences using three measures of communicative behavior. First, we examined accuracy to evaluate whether children were able to succeed at the reference game in collaboration with their parents. Second, we examined conversational turn-taking behavior to evaluate how interactive dialogue may contribute to success. Third, we examined the number of words produced by each partner on each turn to evaluate the efficiency of pacts.

### Performance accuracy

We began by analyzing task performance across age groups. Because pairs of adults were consistently at ceiling throughout the task, we focused on the performance of parent-child pairs. We constructed a mixed-effects logistic regression predicting whether the matcher successfully chose the correct referent on each trial. The model included (continuous) fixed effects of age and repetition block, random intercepts for each tangram and pair of participants, and random effects of repetition block for each pair of participants^[In principle, we were also interested in whether there were differences in accuracy when the child vs. parent was matcher, but our sample is likely underpowered for such a finer-grained analysis within games.].

Initial accuracy was well above chance for all age groups, indicating that even young children can succeed in this referential task with their parents. We also found a significant main effect of age ($\beta$ = `r age_effect_acc$estimate`, $t$ = `r age_effect_acc$statistic`; $p=$ `r papaja::printp(age_effect_acc$p.value)`):  Pairs with younger children performed significantly worse than pairs with older children. Critically, however, accuracy improved significantly over the four repetition blocks for all groups ($\beta$ = `r rep_effect_acc$estimate`, $t$ = `r rep_effect_acc$statistic`, $p$ `r papaja::printp(rep_effect_acc$p.value)`; Fig. \ref{fig:acc_exchanges}A). Such improvement for 4-year-olds contrasts with previous results showing no improvement in accuracy with pairs of kindergarteners [age 5, @krauss1969]. 

> **_TODO:_**  Include analyses breaking down errors by which role kids were playing. I think we found that errors were more likely to happen when kids were *directors* than when kids were *matchers*, which set up our later predictions for the comprehension/production experiments? (i.e. that even young kids seemed to do okay interpreting their parents' instructions, but that even after dialogue exchanges, parents weren't always able to understand the kids' instructions.) 

### Interactive dialogue exchanges

```{r question-marks}
questionMarks <- exchanges_data %>% 
  filter(person == 'parent', role == 'matcher') %>% 
  mutate(containQ = str_detect(utterance, "\\?")) %>% 
  rowwise() %>%
  mutate(age = paste0(c('age', age), collapse = "")) %>%
  group_by(age, containQ) %>% 
  tally() %>% 
  group_by(age) %>%
  mutate(proportion = n / sum(n)) %>%
  ungroup()

questionMarkProportions <- questionMarks %>%
  filter(containQ) %>%
  select(age, proportion) %>%
  pivot_wider(names_from = age, values_from = proportion)

chisq.out <- questionMarks %>% 
  select(age, containQ,n) %>%
  spread(containQ,n) %>% 
  select(-age) %>%
  chisq.test() %>%
  tidy()
```


```{r question-count}
questionMarkCount <- exchanges_data %>% 
  filter(role == "matcher") %>%
  mutate(containQ = str_detect(utterance, "\\?")) %>% 
  rowwise() %>%
  mutate(age = paste0(c('age', age), collapse = "")) %>%
  group_by(person, age, rep_num, target, subid, containQ) %>% 
  tally() %>% 
  group_by(age, person, subid, rep_num, target) %>%
  ungroup() %>%
  pivot_wider(names_from = containQ, values_from = n) %>%
  mutate(`FALSE` = if_else(is.na(`FALSE`), 0, as.numeric(`FALSE`)),
         `TRUE` = if_else(is.na(`TRUE`), 0, as.numeric(`TRUE`))) %>%
  pivot_longer(cols = c(`FALSE`, `TRUE`), names_to = "has_question", 
               values_to = "n") %>%
  group_by(person, age, rep_num, subid, target) %>%
  mutate(prop = n / sum(n)) %>%
  mutate(has_question = as.logical(has_question)) %>%
  filter(has_question) %>%
  group_by(person, age, rep_num, subid) %>%
  summarise(prop = mean(prop), n = mean(n))

questionMarkBooted <- questionMarkCount %>%
  group_by(age, person, rep_num) %>%
  tidyboot_mean(n) 


questionMarkBooted %>%
  ggplot(aes(x = rep_num, y = empirical_stat, color = person)) + 
  facet_grid(. ~ age) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  geom_line()
```

If the ability of children of different ages to successfully establish reference depends on scaffolding provided by their parents, we would expect additional dialogue exchanges for younger children. We quantified dialogue by counting the total number of distinct turns of continuous speech on each trial. 

We  constructed a mixed-effects model predicting the continuous number of exchanges with the same effect structure as reported in the previous section. Consistent with previous work, and replicated in our adult control condition, we found a significant main effect of repetition: Fewer dialogue turns were required on later trials [$\beta$ = `r rep_effect_exchanges$estimate`, $t$ = `r rep_effect_exchanges$statistic`; $p$ `r papaja::printp(rep_effect_exchanges$p.value)`; @clark1986]. In line with our predictions, we also found a significant main effect of age ($\beta$ = `r age_effect_exchanges$estimate`, $t$ = `r age_effect_exchanges$statistic`; $p$ `r papaja::printp(age_effect_exchanges$p.value)`). Pairs with 4-year-old children took roughly one additional turn at each point in the experiment than pairs with older children, who more closely resembled pairs of adults (Fig. \ref{fig:acc_exchanges}B). This increased level of interactivity between parents and younger children provides an interesting contrast with previous studies showing decreased interactivity between pairs of younger children [@anderson1994].

These lengthier exchanges may reflect efforts by parents to provide and elicit additional clarification or confirmation, or may simply reflect attentional difficulties. As a rough estimate of the content of parents' responses when their child was the director, we counted the number of question marks in the transcript^[Because questions were not always annotated with a question mark, this represents a lower bound on the true estimate of questions.]. We found `r questionMarkProportions$age4 * 100`% of responses to 4-year-olds contained question marks, compared to `r questionMarkProportions$age6 * 100`% and `r questionMarkProportions$age8 * 100`% in 6- and 8-year-olds, respectively ($\chi^2(2)=$ `r chisq.out$statistic`, $p$ `r papaja::printp(chisq.out$p.value)`).

### Reduction in length of referential expression

```{r exchange-reduction}
word_exchange_cor = round(cor(d.reduction.raw$numExchanges, d.reduction.raw$num_words),2)

d.reduction.centered <- d.reduction.raw %>% 
  filter(age != 'adult') %>% 
  group_by(subid, person) %>%
  mutate(age = as.numeric(age) - 6,  
         rep_num = as.numeric(rep_num) - 2.5,
         ordinal_rep = if_else(rep_num == first(rep_num), 
                               'first', 'second'))

lmer.reduction.controlled <-  d.reduction.centered %>%  
  lmer(log(normalized_num_words) ~ person * age * rep_num + 
         (1 + rep_num * person | subid) + (1 + rep_num | target), 
       data = ., contrasts = list(person = contr.sum), 
       control = lmerControl('bobyqa')) %>%
  tidy() %>%
  filter(effect == 'fixed')

lmer.reduction.adults <- d.reduction.raw %>%  
  filter(age == 'adult') %>%
  mutate(age = as.numeric(age) - 6,  
         rep_num = as.numeric(rep_num) - 2.5) %>%
  lmer(log(normalized_num_words) ~ rep_num + (rep_num | subid) + (1 | target), 
       data = ., 
       control = lmerControl('bobyqa')) %>%
  tidy() %>%
  filter(effect == 'fixed')

adult_age_effect <- lmer.reduction.adults %>% filter(term == 'rep_num')
```

```{r effects}
age_effect_reduction = lmer.reduction.controlled %>% filter(term == 'age')
age_effect_reduction_pvalue <- round(age_effect_reduction$p.value, 3)
age_effect_reduction_pvalue <- ifelse(age_effect_reduction_pvalue < 0.001, 
                               '< 0.001', paste0(c('=', age_effect_reduction_pvalue), collapse = ' '))

rep_effect_reduction = lmer.reduction.controlled %>% filter(term == 'rep_num')
rep_effect_reduction_pvalue <- round(rep_effect_reduction$p.value, 3)
rep_effect_reduction_pvalue <- ifelse(rep_effect_reduction_pvalue < 0.001, 
                               '< 0.001', paste0(c('=', rep_effect_reduction_pvalue), collapse = ' '))

person_effect_reduction = lmer.reduction.controlled %>% filter(term == 'person1')
person_effect_reduction_pvalue <- round(person_effect_reduction$p.value, 3)
person_effect_reduction_pvalue <- ifelse(person_effect_reduction_pvalue < 0.001, 
                               '< 0.001', paste0(c('=', person_effect_reduction_pvalue), collapse = ' '))

person_age_interaction_reduction = lmer.reduction.controlled %>% filter(term == 'person1:age')
person_age_interaction_reduction_pvalue <- round(person_age_interaction_reduction$p.value, 3)
person_age_interaction_reduction_pvalue <- ifelse(person_age_interaction_reduction_pvalue < 0.001, 
                               '< 0.001', paste0(c('=', person_age_interaction_reduction_pvalue), collapse = ' '))

person_rep_interaction_reduction = lmer.reduction.controlled %>% filter(term == 'person1:rep_num')
person_rep_interaction_reduction_pvalue <- round(person_rep_interaction_reduction$p.value, 3)
person_rep_interaction_reduction_pvalue <- ifelse(person_rep_interaction_reduction_pvalue < 0.001, 
                                                  '< 0.001', paste0(c('= ', person_rep_interaction_reduction_pvalue), collapse = ' '))

age_rep_interaction_reduction = lmer.reduction.controlled %>% filter(term == 'age:rep_num')
age_rep_interaction_reduction_pvalue = round(age_rep_interaction_reduction$p.value, 3)
age_rep_interaction_reduction_pvalue <- ifelse(age_rep_interaction_reduction_pvalue < 0.001, 
                                                  '< 0.001', paste0(c('= ', age_rep_interaction_reduction_pvalue), collapse = ' '))

person_age_rep_interaction_reduction = lmer.reduction.controlled %>% filter(term == 'person1:age:rep_num')
person_age_rep_interaction_reduction_pvalue = round(person_age_rep_interaction_reduction$p.value, 3)
person_age_rep_interaction_reduction_pvalue <- ifelse(person_age_rep_interaction_reduction_pvalue < 0.001, 
                                                  '< 0.001', paste0(c('= ', person_age_rep_interaction_reduction_pvalue), collapse = ' '))
```

```{r reduction, cache=T, fig.env = "figure*", fig.pos = "tb", fig.width=7, fig.height=3, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Total number of words in referential expressions produced by children and parents over the course of interaction."}

reduction_labels = tibble(rep_num = c(3.5, 3.5, 2), 
                          empirical_stat = c(14, 6, 10.5), 
                          person = c("parent", "child", "adult"), 
                          plot_person = c("parent", "child", "adult"),
                          age = c("4", "4", "adult"))

d.reduction.means %>%
  ggplot(aes(x = rep_num, y = empirical_stat, 
             group = person, color = plot_person, label = plot_person)) +
  geom_line(position = position_dodge(.25)) +
  facet_grid(. ~ age) + 
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0,
                position = position_dodge(.25)) +
  geom_text(data = reduction_labels)+
  theme_few() +
  theme(aspect.ratio = 1, legend.position = "none") +
  ylab("# words per exchange") +
  xlab("repetition #") +
  scale_color_manual(values = c(ADULTS, CHILD_SCALE[2], PARENTS))

```

A key signature of successful communication among adults is an increase in efficiency over repeated reference [@clark1986]. As pairs form conceptual pacts, they are able to communicate the same meaning using fewer words. Our control sample of adults replicated this classic effect ($\beta=$ `r adult_age_effect$estimate`, $t=$ `r adult_age_effect$statistic`, `r papaja::printp(adult_age_effect$p.value)`). Here, we asked whether parents and children of different ages spontaneously reduce their referential expressions in the same way. We define referential expressions as all utterances produced by the director on a given trial, up until a selection is made by the matcher. Because the total number of words produced on a trial is correlated with the number of dialogue exchanges examined above ($r=$ `r word_exchange_cor`), we constructed a normalized efficiency measure that controls for additional turns. Specifically, we defined efficiency as the total number of words produced by the *director* divided by the number of dialogue exchanges on that trial. 

Because participants in a pair alternated roles, each participant served as the director twice for each tangram. This structure allowed us to examine how each participant changed their language when they were the director (Fig. \ref{fig:reduction}). Using a mixed-effects model, we predicted the (log) number of words per exchange on each trial, including fixed effects of age, repetition block, and speaker identity (parent vs. child) as well as all of their interactions. We also included random intercepts at the tangram-level and maximal random structure at the dyad level [i.e. intercept, slopes for repetition block and speaker identity, and their interaction; @BarrLevyScheepersTily13_KeepItMaximal]. All variables were centered to allow interpretation of lower-order terms as effects at the average level of the other terms. We found significant main effects of repetition block ($\beta=$ `r rep_effect_reduction$estimate`, $t=$ `r rep_effect_reduction$statistic`, $p$ `r rep_effect_reduction_pvalue`), speaker identity ($\beta=$ `r person_effect_reduction$estimate`, $t=$ `r person_effect_reduction$statistic`, $p$ `r person_effect_reduction_pvalue`), and age ($\beta=$ `r age_effect_reduction$estimate`, $t=$ `r age_effect_reduction$statistic`, $p$ `r age_effect_reduction_pvalue`). All else being equal, directors used fewer words over subsequent repetitions, children used fewer words than their parents, and pairs with older children used fewer words than pairs with younger children. However, these main effects were clarified by several interactions of interest.

First, while parents on average used more words as director than their children did, we found a significant interaction with the child's age ($\beta =$ `r person_age_interaction_reduction$estimate`, $t =$ `r person_age_interaction_reduction$statistic`, $p$ `r  person_age_interaction_reduction_pvalue`). This gap between parent and child utterance length was largest at age 4 but nearly disappeared by age 8. Second, we found that parents reduced their utterance length over time more strongly than children did, holding age group constant ($\beta =$ `r person_rep_interaction_reduction$estimate`, $t=$ `r person_rep_interaction_reduction$statistic`, $p$ `r person_rep_interaction_reduction_pvalue`). Third, having older children in a pair supported stronger reduction overall, ($\beta=$ `r age_rep_interaction_reduction$estimate`, $t=$ `r age_rep_interaction_reduction$statistic`, $p$ `r age_rep_interaction_reduction_pvalue`). 

Finally, an intriguing developmental question is whether reduction changes over the course of development: are 4-year-olds able to become more efficient as common ground is built, in the same way 8-year-olds do? Because parents of different age groups display similar slopes of reduction, this question is addressed by a 3-way interaction. We found that this interaction was not significant ($\beta=$ `r person_age_rep_interaction_reduction$estimate`, $t=$ `r person_age_rep_interaction_reduction$statistic`, $p$ `r person_age_rep_interaction_reduction_pvalue`), although our sample was likely underpowered to detect this higher-order interaction.

```{r matches}
matches <- read_csv(here("data/deidentified/word_matches.csv"),
                    show_col_types = FALSE) %>% 
  filter(later_rep == 4) %>%
  spread(earlier_rep, match) %>%
  mutate(first_appearance = case_when(`1` ~ '1', 
                                      `2` ~ '2', 
                                      `3` ~ '3', 
                                      TRUE ~ 'never'),
         total = length(first_appearance),
         director = final_round_person,
         matcher = case_when(final_round_person == 'left' ~ 'right',
                             final_round_person == 'right' ~ 'left',
                             final_round_person == 'parent' ~ 'child',
                             final_round_person == 'child' ~ 'parent')) %>%
  filter(first_appearance != 'never') %>%
  mutate(introduced_by = ifelse(first_appearance %in% c('2'), 
                                director, matcher),
         #introduced_by_parent = introduced_by == 'parent',
         introduced_on_first_round = first_appearance %in% c('1'),
         introduced_by_self = introduced_by == director,
         introduced_by_other = introduced_by != director,
          director = ifelse(director %in% c('left', 'right'), 
                            'adult', director),
         age = ifelse(is.na(age), 'adult-adult', age))

mean_matches <- matches %>%
  group_by(age, director) %>%
  tidyboot_mean(introduced_by_other)
```

```{r aoa-computation, cache = TRUE}
tokens <- combined_data %>%
  filter(role == "director") %>%
  group_by(age, person, subid, target, rep_num) %>%
  summarise(words = str_to_lower(utterance)) %>%
  ungroup() %>%
  unnest_tokens(word, words) %>%
  ungroup() %>%
  mutate(word = str_to_lower(word))

aoas <- tokens %>%
  left_join(kuperman_aoas, by = "word") %>%
  filter(!word %in% tm::stopwords()) %>%
  group_by(age, person, target, rep_num, subid) %>%
  summarise(aoa = mean(aoa, na.rm = T)) %>%
  group_by(age, person, target, subid) %>%
  ungroup() %>%
  mutate(person = case_when(person == "left" ~ "adult",
                            person == "right" ~ "adult",
                            T ~ person))

mean_aoas <- aoas %>%
  mutate(age = if_else(is.na(age), "adult", as.character(age))) %>%
  group_by(age, person, rep_num, subid) %>%
  summarise(aoa = mean(aoa, na.rm = T)) %>%
  tidyboot_mean(aoa, na.rm = T) %>%
   mutate(plot_person = case_when(person == "adult" ~ "adult",
                                 person == "parent" ~ "parent",
                                 T ~ "child"))

lmer.aoas <- aoas %>%
  filter(!is.na(age)) %>%
  mutate(age = as.numeric(age) - 6, rep_num = rep_num - 2.5) %>%
  lmer(aoa ~ person * age * rep_num + (rep_num * person  | subid) +
         (1 | target), data = ., control = lmerControl(optimizer = "bobyqa")) %>%
  tidy() %>%
  filter(effect == "fixed")
```

```{r origin-effects}
age_effect_origin = lmer.aoas %>% filter(term == 'age')
age_effect_origin_pvalue <- round(age_effect_origin$p.value, 3)
age_effect_origin_pvalue <- ifelse(age_effect_origin_pvalue < 0.001, 
                               '< 0.001', paste0(c('=', age_effect_origin_pvalue),
                                                 collapse = ' '))

rep_effect_origin = lmer.aoas %>% filter(term == 'rep_num')
rep_effect_origin_pvalue <- round(rep_effect_origin$p.value, 3)
rep_effect_origin_pvalue <- ifelse(rep_effect_origin_pvalue < 0.001, 
                               '< 0.001', paste0(c('=', rep_effect_origin_pvalue),
                                                 collapse = ' '))

person_effect_origin = lmer.aoas %>% filter(term == 'personparent')
person_effect_origin_pvalue <- round(person_effect_origin$p.value, 3)
person_effect_origin_pvalue <- ifelse(person_effect_origin_pvalue < 0.001, 
                               '< 0.001', paste0(c('=', person_effect_origin_pvalue), collapse = ' '))

person_age_interaction_origin = lmer.aoas %>% filter(term == 'personparent:age')
person_age_interaction_origin_pvalue <- round(person_age_interaction_origin$p.value, 3)
person_age_interaction_origin_pvalue <- ifelse(person_age_interaction_origin_pvalue < 0.001, 
                               '< 0.001', 
                               paste0(c('=',
                                        person_age_interaction_origin_pvalue), 
                                      collapse = ' '))

person_rep_interaction_origin = lmer.aoas %>% filter(term == 'personparent:rep_num')
person_rep_interaction_origin_pvalue <- round(person_rep_interaction_origin$p.value, 3)
person_rep_interaction_origin_pvalue <- ifelse(person_rep_interaction_origin_pvalue < 0.001, 
                                                  '< 0.001', paste0(c('= ', person_rep_interaction_origin_pvalue), collapse = ' '))

age_rep_interaction_origin = lmer.aoas %>% filter(term == 'age:rep_num')
age_rep_interaction_origin_pvalue = round(age_rep_interaction_origin$p.value, 3)
age_rep_interaction_origin_pvalue <- ifelse(age_rep_interaction_origin_pvalue < 0.001, 
                                                  '< 0.001', paste0(c('= ', age_rep_interaction_origin_pvalue), collapse = ' '))

person_age_rep_interaction_origin = lmer.aoas %>% filter(term == 'personparent:age:rep_num')
person_age_rep_interaction_origin_pvalue = round(person_age_rep_interaction_origin$p.value, 3)
person_age_rep_interaction_origin_pvalue <- ifelse(person_age_rep_interaction_origin_pvalue < 0.001, 
                                                  '< 0.001', paste0(c('= ', person_age_rep_interaction_origin_pvalue), collapse = ' '))
```

```{r origins,  fig.env = "figure*", fig.pos = "tb", fig.width=6, fig.height=3.5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "(A) Probability of words used on final round first occuring with child or parent. (B) Complexity of language used by different age groups estimated from words' average age of acquisition. Error bars are 95\\% CI."}

origins.plt1 <- mean_matches %>%
  #tally() %>%
  ggplot(aes(x = as.numeric(as.factor(age)), y = empirical_stat, 
             group = director, color = director, label = director)) +
    geom_line( position = position_dodge(.25)) +
    geom_point(position = position_dodge(.25)) +
    geom_hline(yintercept = .5, linetype = "dashed") +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0,
                  position = position_dodge(.25)) +
    theme(legend.position="top") +
    ylab('% words introduced by partner') +
    scale_x_continuous(name = "age group", limits = c(.25, 4.25),
                       breaks = 1:4, labels = c("4", "6", "8", "adult")) +
    theme(aspect.ratio = 1, legend.position = "none") +
    guides(color=guide_legend(title="Director")) +
    scale_color_manual(values = c(ADULTS, CHILD_SCALE[2], PARENTS)) +
    labs(tag = 'A') +
    geom_dl(method = list(dl.trans(x = x - .15), "first.points", cex=.8))


aoa_labels = tibble(rep_num = c(2, 1.6, 2), 
                          empirical_stat = c(4.5, 4, 4.1), 
                          plot_person = c("parent", "child", "adult"),
                          plot_age = c("parent", "child", "adult"),
                          age = c("4", "4", "adult"))

origins.plt2 <- ggplot(mean_aoas, aes(x = rep_num, y = empirical_stat,
                                      color = plot_person)) +
  facet_wrap(~ age, ncol = 2) +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper),
                 position = position_dodge(.25)) + 
  geom_line(position = position_dodge(.25)) + 
  theme(aspect.ratio = 1, legend.position = "none") +
  labs(x = "rep #", y = "AoA (average)", tag = "B") +
  scale_color_manual(values = c( ADULTS, CHILD_SCALE[2], PARENTS)) +
  geom_text(aes(label = plot_age), data = aoa_labels)

cowplot::plot_grid(origins.plt1, origins.plt2, axis = 'b', ncol = 2, rel_widths = c(0.52, 0.48))
```

Pairs of age-matched children are notoriously poor at repeated referential communication, failing to coordinate on mutually comprehensible referential expressions [@krauss1977]. Our results demonstrate that children and their parents can solve this coordination problem, converging on increasingly accurate and efficient pacts like pairs of adults. What allows children to coordinate with their parents but not with their peers? 

One possibility is that children lack the ability to *adapt* to their partner: they have a strong preference for a particular idiosyncratic description and are not sensitive to the possibility that their partner may not understand it. Under this hypothesis, children fail with other children because they each continue to use mutually incomprehensible expressions, and only succeed with their parent as a result of the parent's flexibility. Alternatively, young children may be able to adapt successfully but be unable to generate good initial candidate labels. In this case, pairs of children may fail because neither partner can generate good enough labels to start the pact-formation process, while children and parents succeed because parents seed the first good candidate label. 

These accounts make different predictions about who is adapting to who: do pacts originate with children, or with adults? We distinguish these accounts by quantitatively analyzing the natural-language transcripts. 

### Where do pacts come from?

```{r match-model, cache = TRUE}
match.model <- matches %>% 
  filter(experiment == 'adult-child') %>% 
  mutate(age = as.numeric(age) - 6) %>%
  glmer(introduced_by_other ~ age * director + (1 | target) +  (1 | subid), 
        contrasts = list(director = contr.sum),
        data = .,
        control=glmerControl('bobyqa'),
        family = 'binomial') %>%
  tidy()

speaker_effect <- match.model %>% filter(term == 'director1')
match.interaction_effect <- match.model %>% filter(term == 'age:director1')
```

```{r plots-for-talk, eval = FALSE}

#exchanges
d.exchanges.mean %>%
  ggplot(aes(x = rep_num, y = empirical_stat, color = age, 
             group = age, label = age)) +
    geom_line(size = 0.6, position = position_dodge(.25)) +
    geom_point(size = 3, position = position_dodge(.25)) +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0,
                  position = position_dodge(.25)) +
    ylab("Number of exchanges per round") +
    xlab("Repetition") +
    theme(aspect.ratio = 1 / 1.3 , legend.position = "none",
          axis.title = element_text(size = 20),
          axis.text = element_text(size = 18)) +
    scale_color_manual(values = c(rev(COLLAPSED_SCALE), ADULTS)) +
    scale_x_continuous(limits = c(.75, 4.5), breaks = 1:4) + 
    geom_dl(method = list(dl.trans(x = x + .6), "last.qp", cex = 1.5))

#reduction overall
d.reduction.raw %>% 
  group_by(age, rep_num) %>%
  tidyboot_mean(normalized_num_words) %>%
  ggplot(aes(x = rep_num, y = empirical_stat, group = age, color = age)) +
  geom_line(size = 0.6, position = position_dodge(.25)) +
  facet_grid(. ~ age) + 
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0,
                position = position_dodge(.25)) +
  geom_point(size = 3) +
  theme_few() +
  theme(aspect.ratio = 1.5, legend.position = "none", 
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14),
        strip.text = element_text(size = 12)) +
  ylab("Words per exchange") +
  xlab("Repetition") +
  scale_color_manual(values = c(CHILD_SCALE, ADULTS))

#pact origins
mean_matches %>%
  #tally() %>%
  ggplot(aes(x = as.numeric(as.factor(age)), y = empirical_stat, 
             group = director, color = director, label = director)) +
    geom_line(size = .75, position = position_dodge(.25)) +
    geom_point(size = 3, position = position_dodge(.25)) +
    geom_hline(yintercept = .5, linetype = "dashed") +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0,
                  position = position_dodge(.25),
                  size = .75) +
    theme(legend.position="top") +
    ylab('Proportion of words introduced by partner') +
    scale_x_continuous(name = "age group", limits = c(.25, 4.25),
                       breaks = 1:4, labels = c("4", "6", "8", "adult")) +
    theme(aspect.ratio = .8, legend.position = "none",
          axis.title = element_text(size = 18),
          axis.text = element_text(size = 16)) +
    guides(color=guide_legend(title="Director")) +
    scale_color_manual(values = c(ADULTS, CHILD_SCALE[2], PARENTS)) +
    geom_dl(method = list(dl.trans(x = x - .15), "first.points", cex= 1.5), 
            position = position_dodge(.25))

#questions
questionMarks %>%
  filter(containQ == "TRUE") %>%
  mutate(age = gsub(pattern = "age", replacement = "", x = age)) %>%
  ggplot(aes(x = age, y = proportion, fill = age)) +
  theme(legend.position = "none") +
  geom_bar(stat = "identity") +
  xlab("Age") +
  ylab("Proportion of utterances containing questions") +
  theme(plot.margin = unit(c(1, 0, .5, 0), "cm"),
        aspect.ratio = .75, axis.title = element_text(size = 18),
        axis.text = element_text(size = 16)) +
  scale_fill_manual(values = CHILD_SCALE)

#parent feedback
feedback_labels = tibble(rep_num = c(3.5, 3.5, 2), 
                          empirical_stat = c(8.2, 4, 5), 
                          person = c("parent", "child", "adult"), 
                          plot_person = c("parent", "child", "adult"),
                          age = c("4", "4", "adult"))

feedback <- exchanges_data %>%
  mutate(age = ifelse(is.na(age), 'adult', age),
         num_words =  str_count(utterance, " ") +1) %>%
  filter(role == 'matcher') %>%
  mutate(person = ifelse(person %in% c('left', 'right', 'parent'), 'adult', person)) %>%
  group_by(age, rep_num, person, target, subid, trial) %>%
  summarize(numExchanges = n(),
            num_words = sum(num_words)) %>%
  mutate(normalized_num_words = num_words / numExchanges) %>%
  ungroup()

feedback_means <- feedback %>%
  group_by(age, rep_num, person) %>%
  tidyboot_mean(normalized_num_words) %>%
  mutate(plot_person = case_when(age == "adult" ~ "adult",
                                 person == "adult" ~ "parent",
                                 T ~ "child"))

feedback_means %>%
  ggplot(aes(x = rep_num, y = empirical_stat, group = person, color = plot_person,
             label = plot_person)) +
  geom_point(size = 3, position = position_dodge(.25)) +
  geom_line(size = .6, position = position_dodge(.25)) +
  geom_text(size = 5, data = feedback_labels) +
  facet_grid(. ~ age) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0,
                position = position_dodge(.25)) +
  xlab("Repetition") +
  ylab("Words per exchange") +
  scale_color_manual(values = c(ADULTS, CHILD_SCALE[2], PARENTS)) +
  theme_few() +
  theme(aspect.ratio = 1.5, legend.position = "none",
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 14),
        strip.text.x = element_text(size = 14))

lmer.feedback <- feedback %>% 
  filter(age != 'adult') %>%
  mutate(age = as.numeric(age)) %>%
  lmer(log(normalized_num_words) ~ age * person +  (rep_num | subid), 
       control = lmerControl(optimizer = "bobyqa"), data = .) %>%
  tidy() %>%
  filter(effect == "fixed")

```

For each word in the final description of a tangram, we checked whether it had appeared in an earlier referential expression for that tangram. We noted the first trial where it appeared, and who was director when it was produced^[To match different forms of the same word (e.g. "jumping" vs. "jumped") we first lemmatized each word. We also filtered out stop words ("the", "with"), as well as common words that were not part of the pacts ("person", "box"), and excluded words that appeared for the first time on the final repetition of each target.]. The proportion of words originating with the child and parent is shown in Fig. \ref{fig:origins}A. We observed an asymmetry: the words used by children on the final repetition were more likely to have originated with their parents than the words used by parents were to originate with their children. In addition, this gap appeared to close with older groups, with parents more likely to adopt words introduced by older children.

We tested this hypothesized interaction using a mixed-effects logistic model predicting whether each word appearing on the final repetition for each tangram was introduced by the current director or by their partner. We included fixed effects of age group and the speaker identity (parent or child), as well as random intercepts for each pair of participants and each tangram. We found a significant main effect of speaker identity, with the words used by children more likely to originate with their partner than the words used by parents, ($\beta=$ `r speaker_effect$estimate`, $t=$ `r speaker_effect$statistic`, `r papaja::printp(speaker_effect$p.value)`).
Additionally, we found a weak but significant interaction between speaker and age, indicating that this asymmetry was smaller for older children ($\beta=$ `r match.interaction_effect$estimate`, $t=$ `r match.interaction_effect$statistic`, $p=$ `r papaja::printp(match.interaction_effect$p.value)`). Thus, parents---especially parents of younger children---appear to be the source of the words that persist in successful conceptual pacts.

### How do pacts differ across ages?

Given that the labels used by younger children tend to originate with their parents, it is tempting to conclude that adaptation for these pairs is entirely one-sided. However, the resulting pacts may have nonetheless been shaped by children. In particular, we suggest that even though young children may not be able to *supply* good initial labels, they may serve as "simplifiers" or "filters" that constrain the complexity of the resulting pact, since it must pass through their comprehension and production system [@hudson-kam2005].

We tested this hypothesis by asking about the linguistic complexity of the pacts developed in each age group. To estimate the complexity of individual words, we used self-reported age of acquisition (AoA) estimates [@kuperman2012]. Our assumption, based on Kuperman et al.'s work, is that more complex words are harder to acquire, and thus have later ages of acquisition (AoA). To estimate the complexity of referential expressions as a whole, we simply averaged the AoAs of all the words they contained^[We first removed any words in a list of `r length(tm::stopwords())` stop words like "at" and "me" from the \texttt{tm} package [@feinerer2008]]. In all age groups, parents produced more linguistically complex referential expressions than children, but as children get older, both their expressions and their parents' become more linguistically complex over repetitions of the same tangram (like adults) (Fig. \ref{fig:origins}B). 

We confirmed this observation with a mixed-effects model including all possible interactions of age, person (child vs. parent), and repetition number, and maximal random effect structure as before. We found significant main effects of age ($\beta=$ `r age_effect_origin$estimate`, $t =$ `r age_effect_origin$statistic`, $p$`r age_effect_origin_pvalue`), and person ($\beta=$ `r person_effect_origin$estimate`, $t=$ `r person_effect_origin$statistic`, $p$ `r person_effect_origin_pvalue`), but not repetition ($\beta=$ `r rep_effect_origin$estimate`, $t =$ `r rep_effect_origin$statistic`, $p$ `r rep_effect_origin_pvalue`). All else being equal, pairs with older children produced more complex utterances, and parents produced more complex utterances than children. Further, we found a significant interaction between age and repetition number, suggesting that later repetitions became more complex for dyads with older children ($\beta=$ `r age_rep_interaction_origin$estimate`, $t=$ `r age_rep_interaction_origin$statistic`, $p$ `r  age_rep_interaction_origin_pvalue`). This interaction may be driven by reduction processes, as more distinctive words tend to persist as common words are dropped [@hawkins2019]. No other effects were significant, indicating that parents' utterances remained a constant level of complexity above children's even as children's utterances became more complex. These results suggest that pact formation depends not only on parental input, but on children as well---pacts may originate from parents, but children control their complexity.

# Experiment 2: Comprehension

Our first experiment found that young children are able to coordinate on pacts with their parents.
Even four-year-olds readily adopted the labels introduced by their parents and interactively refined their descriptions in response to spontaneous parent-initiated repair.
So why do younger children struggle so much with their peers?
One possibility is that the difficulty lies primarily in the process of *comprehension*. 
Children might be poor listeners.
They may be unable to understand or accommodate their partner's description if it does not align with their own way of conceptualizing the tangram, preventing uptake of a pact.
Another possibility is that the root of the difficulty primarily lies in *production*.
In other words, children may have difficulty *generating* sufficiently descriptive referring expressions on their own, given their limited vocabulary and other processing constraints, but are able to recognize a good description when they hear it, and adopt that description going forward.

In Experiment 2, we tested the first of these two hypotheses using a comprehension task. 
We provided naive children and adults with the descriptions produced by participants in Experiment 1 and asked how well they were able to interpret them.
If comprehension is the root of the developmental problem, we might expect that naive children would be equally unable to interpret all referring expressions (regardless of whether they were originally produced by adults or children) while naive adults would have no difficulty.
Conversely, if naive children are able to understand the referring expressions produced by parents (and not necessarily those by children), then we may expect the source of the difficulty to be elsewhere.

```{r load-comprehension-data}
raw_adult_data <- read_csv(here("data/comprehension/comprehension_adults.csv"),
                           show_col_types = FALSE) %>%
  select(-age) %>%
  filter(!audioid %in% c("67_08", "67_08_b"))

check_correct <- raw_adult_data %>%
  filter(occurrence == "check") %>%
  mutate(check_correct = correct) %>%
  select(subid, check_correct)

passed_check <- check_correct %>%
  group_by(check_correct) %>%
  count() %>%
  pivot_wider(names_from = check_correct, values_from = n) %>%
  clean_names()

# kid data
stims <- read_csv(here("data/comprehension/random_stims.csv"),
                  show_col_types = FALSE) %>%
  select(-c(correct, trial, rightpic, leftpic))

raw_kid_data <- read_csv(here("data/comprehension/kid_comprehension_data.csv"),
                         show_col_types = FALSE) %>%
  filter(!is.na(id)) %>%
  left_join(stims, by = c("id" = "subject", "target")) %>%
  rename(audioid = audio,
         trialnum = trial,
         p_age = age) %>%
  mutate(correct = correct=="Y") %>%
  filter(!audioid %in% c("67_08", "67_08_b"))

```


# Methods

### Participants

`r passed_check$false + passed_check$true$` adults (ages XXX) were recruited from Amazon Mechanical Turk.
YYY children (ages XXX) were recruited from a preschool in the local community to achieve a planned sample of 200 children.
Because of the COVID-19 pandemic, we were forced to terminate data collection early.
Data from `r passed_check$false` pairs were dropped due to failure to complete the study, leaving a final sample of `r passed_check$true` pairs. 

### Stimuli 

We re-recorded all of the referring expressions produced in Exp. 1.

### Design and procedure

Each participants listened to exactly 10 recordings, one for each tangram.
On each trial, the target tangram appeared with the foil from Exp. 1.

### Pre-processing

```{r tidy-data}
database_ids <- read_csv(here("data/databaseid.csv")) %>%
  rename(gameid = subid) %>%
  select(gameid, age)

#gameid is original subject id
tidy_turk_data <- raw_adult_data %>%
  left_join(check_correct, by = c("subid")) %>%
  filter(check_correct, occurrence != "check") %>%
  separate(audioid, into = c("gameid", "gametrial"), sep = "_") %>%
  mutate(gameid = as.numeric(gameid),
         gametrial = as.numeric(gametrial)) %>%
  left_join(database_ids, by = ("gameid")) %>%
  mutate(log_rt = log(reactiontime)) %>%
  pivot_longer(cols = c(correct, reactiontime, log_rt), names_to = "measure")

tidy_kid_data <- raw_kid_data %>%
  separate(audioid, into = c("gameid", "gametrial"), sep = "_") %>%
  mutate(gameid = as.numeric(gameid),
         gametrial = as.numeric(gametrial)) %>%
  left_join(database_ids, by = ("gameid")) %>%
  mutate(log_rt = log(rt)) %>%
  filter(rt < 10000) %>%
  pivot_longer(cols = c(correct, rt, log_rt), names_to = "measure")
  
```

```{r rt-skew}
ggplot(tidy_turk_data %>% filter(measure != "correct"), aes(x = value)) +
  facet_wrap(~ measure, scales = "free") + 
  geom_histogram()

ggplot(tidy_kid_data %>% filter(measure != "correct"), aes(x = value)) +
  facet_wrap(~ measure, scales = "free") + 
  geom_histogram()
```


## Results

Accuracy and RT as a function of age, person, occurrence

```{r descriptive-plots}
subj_data <- tidy_turk_data %>%
  filter(measure != "reactiontime") %>% #exclude 17
  group_by(age, person, occurrence, measure, gameid) %>%
  summarise(value = mean(value))

simple_effects <- subj_data %>%
  tidyboot_mean(value)

simple_effects %>% 
  ggplot(aes(x = as.factor(age), y = empirical_stat, color = person)) +
  facet_grid(measure ~ occurrence, scales = "free") + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(.5)) +
  theme_few()

#kid plots
kid_subj_data <- tidy_kid_data %>%
  filter(measure != "rt") %>% #exclude 17
  group_by(age, person, occurrence, measure, gameid) %>%
  summarise(value = mean(value))

kid_simple_effects <- kid_subj_data %>%
  tidyboot_mean(value)

kid_simple_effects %>% 
  ggplot(aes(x = as.factor(age), y = empirical_stat, color = person)) +
  facet_grid(measure ~ occurrence, scales = "free") + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(.5)) +
  theme_few()
```

Models from Pre-reg

We will fit a logistic mixed effects model predicting informativeness from person (parent/child), age of child in the pair (4, 6, 8), trial (1 vs 2) and all of their interactions.

```{r full-acc-lmer}
full_acc_lmer <- tidy_turk_data %>%
  filter(measure == "correct") %>%
  glmer(value ~ person * age * occurrence + 
                   (1|target) ,
       family = "binomial", data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  select(-effect, -group)

full_acc_lmer

#kid model

kid_full_acc_lmer <- tidy_kid_data %>%
  filter(measure == "correct") %>%
  glmer(value ~ person * age * occurrence + 
                   (1|target) ,
       family = "binomial", data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  select(-effect, -group)

kid_full_acc_lmer

```

```{r reduced-acc-lmer}
acc_lmer <- tidy_turk_data %>%
  filter(measure == "correct") %>%
  glmer(value ~ person + age + occurrence  + 
                   (1|target) + (1|subid), 
        family = "binomial", data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  select(-effect, -group)

acc_lmer

#kid model
kid_acc_lmer <- tidy_kid_data %>%
  filter(measure == "correct") %>%
  glmer(value ~ person + age + occurrence  + 
                   (1|target) + (1|subid), 
        family = "binomial", data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  select(-effect, -group)

kid_acc_lmer

#two-way
kid_two_way_lmer <- tidy_kid_data %>%
  filter(measure == "correct") %>%
  glmer(value ~ person*occurrence + age + 
                   (1|target) + (1|subid), 
        family = "binomial", data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  select(-effect, -group)

kid_two_way_lmer

```

```{r full-rt-lmer}
full_rt_lmer <- tidy_turk_data %>%
  filter(measure == "log_rt") %>%
  lmer(value ~ person * age * occurrence + 
                   (1|target) + (1|subid), data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  select(-effect, -group)

full_rt_lmer
```

```{r reduced-rt-lmer}
rt_lmer <- tidy_turk_data %>%
  filter(measure == "log_rt") %>%
  lmer(value ~ person + age + occurrence  + 
                   (1|target) + (1|subid), data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  select(-effect, -group)

rt_lmer
```


So parents' descriptions lead to more accurate and faster guesses. Both older kids and parents of older kids give better descriptions. 

But no effect of occurrence--descriptions on the second appearance of each item do not appear to contain less information for guessing the target.

```{r exchange-data}
exchange_data <- read_csv(here("data/exchange_data.csv")) %>%
  select(subid, trial, director, person, num_exchanges) %>%
  group_by(trial, subid) %>%
  summarise(num_exchanges = sum(num_exchanges))

turk_exchange_data <- tidy_turk_data %>% left_join(exchange_data, 
                                                   by = c("gameid" = "subid"),
                                                   "gametrial" = "trial")

turk_exchange_data %>%
  filter(measure == "correct") %>%
  group_by(age, num_exchanges, person) %>%
  summarise(value = mean(value)) %>%
  ggplot(aes(x = num_exchanges, y = value, color = as.factor(age))) +
  facet_wrap(~ person) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE)
```

# Experiment 3: Production experiment

We ran a production experiment.

```{r anonymize-e2-data, eval = FALSE}
#anonymize
read_csv(here("data/production/dataFromMongo.csv"))%>%
  filter(trial_type == "survey-text") %>%
  filter(iterationName == "pilot2") %>%
  mutate(wID = as.numeric(as.factor(wID))) %>%
  write_csv(here('./data/production/anonymizedDataFromMongo.csv'))
```

```{r e2-data}
d.prod.raw <- read_csv(here("data/production/anonymizedDataFromMongo.csv"),
                       show_col_types = FALSE)
  
complete_games <- d.prod.raw %>%
  group_by(wID) %>%
  tally() %>%
  filter(n == 48) %>%
  pull(wID)

cat('we have', length(complete_games), 'games')

d.prod <- d.prod.raw %>%
  filter(wID %in% complete_games) %>%
  filter(rt > 1000) %>%
  mutate(utterance = str_to_lower(utterance),
         utterance = str_trim(utterance),
         utt_length = str_length(utterance),
         clean_utt = lemmatize_strings(utterance),
         clean_utt = str_remove_all(clean_utt, pattern = ' '))

#write.csv(d.prod, "data/production/pilot_data_lemmatized.csv")

d.prod.clean <- read_csv(here("data/production/pilot_data_clean.csv"),
                         show_col_types = FALSE) 
  #filter(utt_length > 1) #%>%
  #mutate(clean_utt = lemmatize_words(clean_utt))
  
```

## Response times reflect familiarity and context

We examined log response times.

```{r e2-rts}
# overall RT distribution

d.prod.raw %>%
  mutate(logged_rt = log(rt)) %>%
  gather(measure, value, logged_rt, rt) %>%
  ggplot(aes(x = value)) +
    geom_histogram() +
    facet_wrap(~ measure, scales='free')

d.prod %>%
  mutate(logged_rt = log(rt)) %>%
  gather(measure, value, logged_rt, rt) %>%
  ggplot(aes(x = value)) +
    geom_histogram() +
    facet_wrap(~ measure, scales='free')
```
  
```{r}
ggplot(d.prod, aes(x = target_type, y = log(rt), color = competitor_type)) +
  geom_boxplot() +
  theme(legend.position = 'top')
```

```{r}
d.prod %>%
  lm(log(rt) ~ target_type * competitor_type, 
     data = .) %>%
  tidy()
```

## Variability in labels 

```{r}
dodge = position_dodge(0.9)
d.prod %>%
  group_by(target_type, competitor_type) %>%
  tidyboot_mean(utt_length) %>%
  ggplot(aes(x = target_type, y = empirical_stat, fill = competitor_type)) +
    geom_bar(stat='identity', position=dodge) +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0, position=dodge) +
    labs(x = "target type",
         y = "utterance length") +
    theme(legend.position = 'top')
```

We considered several measures of codability/overlap:

* total number of unique labels (when people overlap a lot, this is smaller because we collect the same number of labels for each target; warning, this could be misleading if we're dropping trials due to high rts and some conditions have more dropped)
* proportion of unique labels to total labels (fixes this problem, but still doesn't account for the distribution of overlap, e.g. if one gets hit 10 times and others get hit 1 vs. everything gets hit 2 times.)
* entropy (we all know and love)
* codeability (what proportion of people provided the most common label, if there were 40 labels and 20 were 'bird', this would be 50%)

```{r}
d.prod %>%
  group_by(target_type, competitor_type, utterance, target) %>%
  tally() %>%
  arrange(target) %>%
  group_by(target_type, competitor_type) %>%
  mutate(total_labels = sum(n)) %>%
  summarize(unique_labels = length(n), 
            normalized_unique_labels = mean(unique_labels) /  mean(total_labels),
            entropy = entropy(n, method="SG"),
            normalized_entropy = mean(entropy) / log(length(n)),
            codeability = max(n) / sum(n)) %>%
  gather(measure, value, unique_labels:codeability) %>%
  group_by(target_type, competitor_type, measure) %>%
  tidyboot_mean(value) %>%
  ggplot(aes(x = target_type, y = empirical_stat, fill = competitor_type)) +
    geom_bar(stat = 'identity', position=dodge) +
    facet_grid(measure ~. , scales='free') +
    theme(legend.position = "top")

ggsave('variability_measures_clean.pdf', width = 10, height = 10, unit = 'in')

#compare with old data
d.prod.old <- read_csv(here("data/production/pilot_data_clean.csv"))

d.prod.old %>% 
  group_by(target_type, competitor_type, utterance, target) %>%
  tally() %>%
  arrange(target) %>%
  group_by(target_type, competitor_type) %>%
  mutate(total_labels = sum(n)) %>%
  summarize(unique_labels = length(n), 
            normalized_unique_labels = mean(unique_labels) / mean(total_labels),
            entropy = entropy(n, method="SG"),
            normalized_entropy = mean(entropy) / log(length(n)),
            codeability = max(n) / sum(n)) %>%
  gather(measure, value, unique_labels:codeability) %>%
  group_by(target_type, competitor_type, measure) %>%
  tidyboot_mean(value) %>%
  ggplot(aes(x = target_type, y = empirical_stat, fill = competitor_type)) +
    geom_bar(stat = 'identity', position=dodge) +
    facet_grid(measure ~. , scales='free')

```


```{r regression model comparing competitor types}

prod.model <- d.prod %>%
  group_by(target_type, competitor_type, utterance, target) %>%
  tally() %>%
  arrange(target) %>%
  group_by(target_type, competitor_type, target) %>%
  mutate(total_labels = sum(n)) %>%
  summarize(unique_labels = length(n), 
            normalized_unique_labels = mean(unique_labels) / mean(total_labels),
            entropy = entropy(n, method="SG"),
            normalized_entropy = mean(entropy) / log(length(n)),
            codeability = max(n) / sum(n))

prod.model %>%
  lmer(codeability ~ target_type*competitor_type + (1|target), data =.) %>%
  tidy() %>%
  filter(effect == "fixed")

```

```{r comparing-distributions}
kl_drop <- function(df, x1, x2) {
  x1 <- enquo(x1)
  x2 <- enquo(x2)
  # 
  df %>%
    filter(!!x1 != 0 | !!x2 != 0) %>%
    summarise(kl = KL.shrink(!!x1, !!x2)) %>%
    pull(kl)
}

kls <- d.prod %>%
  count(target_type, competitor_type, target, clean_utt) %>%
  complete(nesting(target_type, target), competitor_type, clean_utt, 
           fill = list(n = 0)) %>%
  pivot_wider(names_from = competitor_type, values_from = n) %>%
  group_by(target_type, target) %>%
  nest() %>%
  mutate(close_far = map(data, ~kl_drop(.x,close, far)),
         isolated_far = map(data, ~kl_drop(.x,isolated, far)),
         isolated_close = map(data, ~kl_drop(.x, close, isolated))) %>%
  unnest(cols = c(close_far, isolated_far, isolated_close)) %>%
  select(-data) %>%
  pivot_longer(cols = c(close_far, isolated_far, isolated_close), 
               names_to = "comparison", values_to = "kl")


ggplot(kls, aes(x = comparison, y = kl)) + 
  facet_wrap(~ target_type) + 
  geom_boxplot()

```

```{r scatterplots}

#Look at codeability, etc., as a function of our norming data 
norming_overlap <- read_csv(here("data/norming/jsPsychStims.csv")) %>%
  select(target, overlap_diff) %>%
  right_join(kls, by = "target") %>%
  filter(target_type == "tangram")

ggplot(norming_overlap, aes(x = overlap_diff, y = kl)) +
  geom_point() +
  facet_wrap(~comparison)

```


# Measuring similarity within participant

* within-participant version: For a particular participant, measure whether they use the same word across competition_type conditions for same targets. 

```{r}
normalized_lv <- function(s1, s2) {
  lv_dist = stringdist::stringdist(s1, s2, method = 'lv')
  s1_len <- str_length(s1)
  s2_len <- str_length(s2)
  maxlength = pmax(s1_len, s2_len)
  return(lv_dist / maxlength)
}

indiv_measures <- d.prod %>%
  pivot_longer(cols = c(utterance, clean_utt), 
               names_to = "type", values_to = "utterance") %>%
  select(wID, target, target_type, competitor_type, type, utterance) %>%
  group_by(wID, target_type, target, type) %>%
  spread(competitor_type, utterance) %>%
  filter(!is.na(close), !is.na(far), !is.na(isolated)) %>%
  mutate(close_far.distance = normalized_lv(close, far),
         close_isolated.distance = normalized_lv(close, isolated),
         far_isolated.distance = normalized_lv(far, isolated),
         close_far.match = close == far,
         close_isolated.match = close == isolated,
         far_isolated.match = far == isolated) %>%
  gather(pair, distance, close_far.distance:far_isolated.match) %>%
  group_by(target_type, pair, type) %>%
  tidyboot_mean(distance) %>%
  separate(pair, sep = '\\.', into = c('pair', 'measure')) %>%
  arrange(measure)
```


# Tangram label norming 

Our current hypothesis is that we're not getting context effects for adults in this pilot because even the 'close' contexts aren't close along the actual representational dimensions people are using to label things. So if their labeling prior in isolation is to say it's 'sad', that's still highly informative in the close context because the distractor doesn't look sad at all and there's no pressure being put on the prior (kids likely have very different priors, e.g. 'guy' or 'person' with high probability, so these same contexts probably would put pressure on them). To do this in adults, we probably need to elicit priors in isolation for more tangrams (e.g. all 40) and then design better 'close' contexts where we put together tangrams where adults have very similar priors. Maybe the same for kids.

```{r anonymize-norming-data, eval = FALSE}
# anonymize raw csv
read_csv(here('data/norming/dataFromMongo.csv')) %>%
  filter(iterationName %in% c('full_sample', 'full_sample2')) %>%
  filter(trial_type == 'survey-text') %>%
  mutate(wID = as.numeric(as.factor(wID))) %>%
  write_csv(here('./data/norming/anonymizedDataFromMongo.csv'))
```

```{r load-norming-data}
# take the first 31 rows of each wID. 
# gets the first game of people who did it twice -- Mongo returns objectIDs in order of insertion date
d.raw.labels <- read_csv(here("data/norming/anonymizedDataFromMongo.csv")) 

initialAssignmentIDs <- d.raw.labels %>%
  group_by(wID) %>%
  summarize(firstAssignmentID = first(aID)) %>%
  pull(firstAssignmentID)

complete_games <- d.raw.labels %>%
  filter(aID %in% initialAssignmentIDs) %>%
  group_by(wID) %>%
  tally() %>%
  filter(n == 31) %>%
  pull(wID)

passed_catch <- d.raw.labels %>%
  filter(target_type == 'catch') %>%
  mutate(utterance = tolower(utterance)) %>%
  filter(utterance == 'strawberry') %>%
  pull(wID)

d <- d.raw.labels %>%
  filter(wID %in% complete_games) %>%
  filter(wID %in% passed_catch) %>%
  filter(target_type != 'catch') %>%
  mutate(clean_utt = tolower(utterance),
         lemmatized_utt = lemmatize_words(clean_utt),
         lemmatized_utt = str_replace_all(lemmatized_utt, regex("\\W+"), ""))
```

How unbalanced is our sample across targets?

```{r}
d %>%
  group_by(target) %>%
  tally() %>%
  ggplot(aes(x = n)) +
    geom_histogram(bins = 5)
```

check RTs

```{r eval = FALSE}
d %>%
  group_by(wID) %>%
  arrange(trial_index) %>%
  mutate(rep = (lemmatized_utt == lag(lemmatized_utt, 1) &
                lemmatized_utt == lag(lemmatized_utt, 2))) %>%
  filter(rep) %>%
  arrange(wID) 
  # group_by(wID) %>%
  # summarize(meanRT = mean(rt)) %>%
  filter(rt < 2000)
  ggplot(aes(x = meanRT)) +
    geom_histogram(bins = 20)

```

Find most similar sets by JS/KL divergence

```{r get-pair-kl}
get_pair_data <- function(df, tangram1, tangram2) {
  df %>%
    filter(target == tangram1) %>%
    select(lemmatized_utt, n) %>%
    rename(target_n = n) %>%
    left_join(df %>%
                filter(target == tangram2) %>%
                select(lemmatized_utt, n),
              by = "lemmatized_utt") %>%
    rename(comparison_n = n)
}

# TODO: take all pairwise comparisons
completed_data <- d %>%
  count(target, lemmatized_utt) %>%
  complete(target, lemmatized_utt, 
           fill = list(n = 0)) 

pairs <- d %>% 
  distinct(target) %>%
  pull() %>%
  combn(2) %>%
  t() %>%
  as_tibble(.name_repair = "unique") %>%
  rename(tangram1 = `...1`, tangram2 = `...2`) %>%
  mutate(target_id = tangram1,
         comparison_id = tangram2) %>%
  group_by(target_id, comparison_id) %>%
  nest() 
```

# Try a simpler, non-KL measure of overlap

```{r overlap-helpers}
check_overlap <- function(df, x1, x2) {
  x1 <- enquo(x1)
  x2 <- enquo(x2)
  df %>%
    filter(!!x1 > 0) %>%
    mutate(prop = !!x1 / sum(!!x1)) %>%
    filter(!!x2 > 0) %>%
    summarise(overlap = sum(prop))
}
  
flip_target_competitior <- function(df, x1, x2) {
  x1 <- enquo(x1)
  x2 <- enquo(x2)
  
  df %>%
    mutate(tmp = !!x1, 
           !!x1 := !!x2, 
          !!x2 := tmp) %>%
    select(-tmp)
}
```

```{r simulate-overlap, eval = FALSE}
get_average_overlap <- function(input_data) {
  flipped_pairs <- pairs %>%
    #flip_target_competitior(.,target_id, comparison_id) %>%
    mutate(data = map(data, ~flip_target_competitior(.x, tangram1, tangram2)))
  
  symmetric_overlap <- pairs %>%
    bind_rows(flipped_pairs) %>%
    ungroup() %>%
    # slice_head(n = 1) %>%
    mutate(overlap = map(data, ~ {
      get_pair_data(input_data, .x$tangram1, .x$tangram2) %>%
      check_overlap(., target_n, comparison_n)
    })) %>%
    select(-data) %>%
    unnest(cols = overlap)
  
  symmetric_overlap %>%
    group_by(target_id, comparison_id) %>%
    summarise(overlap = mean(overlap), n= n())
}

ps <- d %>%
  distinct(wID)

first_half <- d %>%
  filter(wID %in% (slice(ps, 1:(n()/2)) %>% pull(wID))) %>%
  count(target, lemmatized_utt) %>%
  complete(target, lemmatized_utt, 
           fill = list(n = 0)) %>%
  get_average_overlap()

second_half <- d %>%
  filter(wID %in% (slice(ps, ((n()/2)+1):(n())) %>% pull(wID))) %>%
  count(target, lemmatized_utt) %>%
  complete(target, lemmatized_utt, 
           fill = list(n = 0)) %>%
  get_average_overlap()

# correlation b/w split data
first_half %>%
  rename(first_half = overlap) %>%
  left_join(second_half, by = c("target_id", "comparison_id", "n")) %>%
  summarise(cor = cor(first_half, overlap, method = "spearman")) %>%
  summarise(cor = mean(cor, na.rm = T))

overall <- d %>%
  #filter(!(target %in% c("R1.jpg", "O1.jpg"))) %>%
  #mutate(target = as.factor(target)) %>%
  count(target, lemmatized_utt) %>%
  complete(target, lemmatized_utt, 
           fill = list(n = 0)) %>%
  get_average_overlap()
```

look at all pairwise comparisons...

```{r plot-overlap, eval = FALSE} 
ggplot(symmetric_overlap, aes(x = target_id, y = comparison_id, fill = log1p(overlap))) + 
  geom_tile() +
  theme(legend.position = 'right')
```

```{r pilot-items, eval = FALSE}
pilot_items <- d.prod.clean %>% 
  filter(target_type == "tangram", competitor_type != "isolated") %>%
  distinct(target, foil, competitor_type) %>%
  rename(target_id = target, comparison_id = foil) %>%
  left_join(symmetric_overlap, by = c("target_id", "comparison_id"))

pilot_items %>%
  group_by(competitor_type) %>%
  tidyboot_mean(overlap)
```

```{r, eval = FALSE}
pilot_items %>%
  ggplot(aes(x = competitor_type, y = overlap)) +
    geom_jitter(width = .1, height = .1) +
    geom_boxplot(alpha = .5)
```

```{r, eval = FALSE}
pairs %>%
  arrange(kl) 
```

highest and lowest overlap pairs
```{r overall overlap, eval = FALSE}

dissimilar <- overall %>%
  filter(!(target_id %in% c("R1.jpg", "O1.jpg"))) %>%
  filter(!(comparison_id %in% c("R1.jpg", "O1.jpg"))) %>%
  arrange(overlap) %>%
  filter(overlap < median(overlap)) %>%
  filter(!duplicated(target_id)) %>%
  mutate(dissimilar = comparison_id,
         dvalue = overlap) %>%
  select(-c(comparison_id, overlap, n))

similar <- overall %>%
  filter(!(target_id %in% c("R1.jpg", "O1.jpg"))) %>%
  filter(!(comparison_id %in% c("R1.jpg", "O1.jpg"))) %>%
  filter(overlap > median(overlap)) %>%
  arrange(desc(overlap)) %>%
  filter(!duplicated(target_id)) %>%
  mutate(similar = comparison_id,
         svalue = overlap) %>%
  select(-c(comparison_id, overlap, n))

#TODO: Tangrams that have high and low similarity matches

matches <- left_join(dissimilar, similar, by = "target_id") %>%
  arrange(dvalue, desc(svalue)) %>%
  write.csv(here("data/norming/high_low_matches.csv"))
  
#matches <- overall %>%
#  filter(!(target_id %in% c("R1.jpg", "O1.jpg"))) %>%
#  filter(!(comparison_id %in% c("R1.jpg", "O1.jpg"))) %>%
#  filter(target_id %in% c(dissimilar$target_id, dissimilar$comparison_id) |
#        comparison_id %in% c(dissimilar$target_id, dissimilar$comparison_id)) %>%
#  arrange(desc(overlap))

# function to find targets with high and low similarity matches

#df = NULL

#match_pairs <- function(data, comparison){
#  for (i in 1:data.length) {
#    ifelse (data$target_id %in% c(comparison$target_id, comparison$comparison_id) |
#        comparison_id %in% c(comparison$target_id, comparison$comparison_id), 
#        bind_rows(data[i,], df), return)
#  }
#}



```

# adversarial context design


# Discussion

The ability to collaborate with conversational partners on intended meaning is crucial for successful communication. It may be especially important to achieve successful communication with *children*, who regularly encounter novel objects and situations they do not yet have precise words for. In this study, we used a classic repeated reference game to investigate the collaborative processes at play in interactions between parents and their children. While children often struggle to succeed in such games with their peers, we found that even young children were able to successfully form referential pacts with their parents: Accuracy increased, fewer turns were taken, and utterances gradually became shorter over the course of interaction. Furthermore, our results exposed key differences in parental behavior across ages: parents of younger children engaged in more conversational turns, asked more questions, produced longer referential expressions per turn, and adopted less complex labels. These findings indicate that parents may spontaneously adopt some of the strategies used in training studies [e.g. @matthews2007] to scaffold pact formation with their children.

Our results also contribute to the debate over why children may struggle to form referential pacts with each other. One family of explanations has suggested that children simply cannot take their partner's perspective into account, and produce references only they understand [@krauss1977], or cannot judge which expressions are more informative in the first place, even for themselves [@robinson1977; @asher1976]. An alternative account is that errors may partly arise from children's difficulty in the role of matcher: They may struggle to provide sufficient feedback to their partner or ask for clarification when it is necessary [@anderson1994].

While we find some support for each of these accounts in our data, our analysis of the asymmetry in the introduction of pacts suggests an additional possibility: Young children may simply be unable to supply a good enough label on their own, possibly due to limited expertise in identifying and labeling the most informative features of novel objects. Once presented with an appropriate label from a parent, however, they will readily adopt and use it. In this way, the processes underlying the mutual "learning" of referential pacts, in the service of coordinating on meaning with a specific partner, may be the same as those underlying language acquisition. Thus the everyday interaction of parents and children trying to understand one another may not only scaffold local pact formation, but support communicative development more broadly.

# Acknowledgements

This research was funded by a James S. McDonnell Foundation Scholar Award to the last author.

\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
