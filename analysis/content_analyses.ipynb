{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.attrs import POS\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_utils import get_feats, lemmatize_doc\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.matutils import sparse2full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: do something more principled here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop (t) :\n",
    "    return t.is_stop or t.lemma_ in ['person', 'tangrams', 'tangram', 'look', 'like', 'tap', 'choose', 'zzz', 'xxx', 'yyy', 'pick', 'guy', 'blue', 'box']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-process text by lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_raw = pd.read_csv('../deidentified/combined.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_raw['text'] = [nlp(text) for text in d_raw['utterance']]\n",
    "d_raw['non_stop_text'] = [[token for token in text if not token.is_stop] for text in d_raw['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_raw['lemmatized_nonstop'] = [lemmatize_doc(parsed_text) for parsed_text in d_raw['non_stop_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d_raw.copy()\n",
    "gameidList = pd.unique(d.subid.ravel()).tolist()\n",
    "tangramList = pd.unique(d.target.ravel()).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at where conventions were introduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first-order case is where you just look at how often final words occurred at each previous round (percentage).\n",
    "\n",
    "Then we can look at *first* round for each particular word... \n",
    "\n",
    "Then we can check who was speaker on that first round.\n",
    "\n",
    "TODO: check cases where the 'matcher' on a round may have introduced a word\n",
    "\n",
    "TODO: Split on PMI distribution as more systematic way of finding stop words... \n",
    "\n",
    "TODO: look at P(r + 1 | r) for local 'stickiness'\n",
    "\n",
    "TODO: potentially add back in messages sent after selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "def stop (t) :\n",
    "    return t.is_stop or t.lemma_ in ['person', 'look', 'like', 'tap', 'choose', 'zzz', 'xxx', 'yyy', 'pick', 'guy', 'blue', 'box']\n",
    "\n",
    "# For each game, look at referring expressions produced by director on later round\n",
    "for name, df in d.query('role == \"director\"').groupby(['subid', 'rep_num']) :\n",
    "    for i, row in df.sort_values('target').reset_index().iterrows() :\n",
    "        later_rep = row['rep_num']\n",
    "        target = row['target']\n",
    "        content_words = np.unique(\n",
    "            [t.lemma_ for t in row.text \n",
    "             if t.pos_ in [\"NOUN\", \"ADJ\", 'VERB'] \n",
    "             and not stop(t)]\n",
    "        )\n",
    "        query_str = 'target == \"{}\"'.format(target)\n",
    "        for j, word in enumerate(content_words) :\n",
    "            for earlier_rep in range(1, later_rep) :\n",
    "                earlier_df = d.query('rep_num == {} and role == \"director\" and subid == \"{}\"'\n",
    "                                     .format(earlier_rep, name[0])).sort_values('target').reset_index()\n",
    "                match = word in np.array(list(earlier_df.query(query_str)['lemmas'])).flatten()\n",
    "                rows.append([row['experiment'], row['subid'], row['target'], row['person'], row['age'], earlier_rep, later_rep, word, match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame(rows,\n",
    "    columns = ['experiment', 'subid', 'target', 'final_round_person', 'age',\n",
    "               'earlier_rep', 'later_rep',  'word', 'match']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.to_csv('../deidentified/word_matches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the inverse: probability of words on current round appearing at end... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "# For each game, look at referring expressions produced by director on final round\n",
    "for name, rep_df in d.query('role == \"director\"').groupby(['subid', 'rep_num']) :\n",
    "    rep_df = rep_df.sort_values('target').reset_index()\n",
    "    final_df = d.query('rep_num == 4 and role == \"director\" and subid == \"{}\"'.format(name[0])).sort_values('target').reset_index()\n",
    "    \n",
    "    # For each word used with each tangram, check whether it occured in each earlier round\n",
    "    for i, row in rep_df.iterrows() :\n",
    "        target = row['target']\n",
    "        content_words = [t.lemma_ for t in row.text \n",
    "                         if t.pos_ in [\"NOUN\", \"ADJ\", 'VERB'] \n",
    "                         and not stop(t)]\n",
    "        print('content', content_words)\n",
    "        query_str = 'target == \"{}\"'.format(target)\n",
    "        print(np.array(list(final_df.query(query_str)['lemmas'])).flatten())\n",
    "        for j, word in enumerate(content_words) :\n",
    "            final_match = word in np.array(list(final_df.query(query_str)['lemmas'])).flatten()\n",
    "            rows.append([row['experiment'], row['subid'], row['rep_num'], row['target'], row['person'], row['age'], word, final_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame(rows,\n",
    "    columns = ['experiment', 'subid', 'rep_num', 'target', 'person', 'age', 'word', 'final_match']\n",
    ")\n",
    "words_df.to_csv('../deidentified/inverse_word_matches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine semantic embeddings\n",
    "We'd like to pull out bag of words embeddings from NPs in each utterance in the cued dataset and cluster them for each tangram; expect to see different pairs in different parts of the space (i.e. to compute a d' for an 'idiosyncracy' or 'multiple equilibria' result) and also different utterances from single games closer together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_raw = (pd.read_csv('../data/deidentified/tangram_recording_clean.csv')\n",
    "         .rename(columns={'utterance' : 'garbage', 'record' : 'utterance'})\n",
    "         .query('utterance != \"x\"'))\n",
    "d_raw = d_raw[pd.notnull(d_raw.utterance)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_raw['text'] = [nlp(text) for text in d_raw['utterance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_raw['contentful'] = [[t.lemma_ for t in text if t.pos_ not in ['PRON', 'DET', 'CCONJ', 'ADP', 'AUX']] \n",
    "                       for text in d_raw['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_embedding = np.full((1,300), np.nan)\n",
    "def get_feats(d_in, nlp, scramble = False) :\n",
    "    # only look at director utterances\n",
    "    d = d_in.copy()\n",
    "\n",
    "    # initialize feature vector\n",
    "    raw_avg_feats = np.array([]).reshape(0, 300)\n",
    "\n",
    "    if scramble :\n",
    "        d = scramble_words(d)\n",
    "        \n",
    "    for i, row in d.iterrows() :\n",
    "        local_embedding = np.array([]).reshape(0, 300)\n",
    "        for token in row['contentful'] :\n",
    "            if nlp(token).has_vector and sum(nlp(token).vector) != 0:\n",
    "                local_embedding = np.vstack((local_embedding, nlp(token).vector))\n",
    "            else :\n",
    "                print(row['contentful'])\n",
    "                print('no vector available:', nlp(token))\n",
    "\n",
    "        # average them together, handling empty lists\n",
    "        if row['contentful'] :\n",
    "            raw_avg_embedding = np.nanmean(local_embedding, axis = 0) \n",
    "        else :\n",
    "            \n",
    "            raw_avg_embedding = null_embedding.copy()\n",
    "            row['is_null'] = True\n",
    "            \n",
    "        # add to overall list\n",
    "        raw_avg_feats = np.vstack((raw_avg_feats, raw_avg_embedding))\n",
    "    return d, raw_avg_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta, raw_avg_feats = get_feats(d_raw, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(meta\n",
    " .drop(columns = [ 'utterance', 'contentful'])\n",
    " .to_csv('../data/deidentified/meta_tangrams_embeddings.csv'))\n",
    "np.save('../data/deidentified/feats_tangrams_embeddings_rawavg.npy', raw_avg_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at tsne visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "tsne = TSNE(n_components = 2)\n",
    "big_pca = PCA(n_components = 40)\n",
    "viz_pca = PCA(n_components = 2)\n",
    "mds = MDS(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_viz = pd.DataFrame(\n",
    "    columns = ['subid', 'target', 'trial', 'rep_num', 'x_tsne', 'y_tsne', 'x_mds', 'y_mds', 'feats_type']\n",
    ")\n",
    "\n",
    "for name, group in meta.reset_index(drop=True).groupby('target') :\n",
    "    tangram_inds = np.array(group.index)\n",
    "    feats = raw_avg_feats\n",
    "    relevant_feats = feats[tangram_inds]\n",
    "    \n",
    "    # You can't run tsne with NANs, so we have to take them out and then add them back in...\n",
    "    nan_rows = [i for i in range(relevant_feats.shape[0]) if pd.isna(relevant_feats[i,0])]\n",
    "    nan_insert_rows = [k - lag for (lag, k) in enumerate(nan_rows)]\n",
    "    X = np.ma.masked_invalid(relevant_feats)\n",
    "    tsne_out = tsne.fit_transform(big_pca.fit_transform(np.ma.compress_rows(X)))\n",
    "    tsne_out = np.insert(tsne_out, nan_insert_rows, np.nan, axis=0)\n",
    "    X_tsne = pd.DataFrame(tsne_out, columns = ['x_tsne', 'y_tsne'], index=tangram_inds) \n",
    "    embedding_viz = embedding_viz.append(pd.concat([group, X_tsne], axis = 1), \n",
    "                                         ignore_index=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_viz.drop(columns=['text', 'contentful']).to_csv('../data/deidentified/tsne_embeddings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
